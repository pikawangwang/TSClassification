{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8e24f3-08ab-4d61-bfa7-b2bc114dd31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c63686-31c0-41d3-ab33-405010fa004c",
   "metadata": {},
   "source": [
    "# Get segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda8f45a-edb6-4dd2-99c9-88b88d4f7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('noninvasive_data.csv')\n",
    "data['time'] = (data['time'] * 3 - 360).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04dbb75e-39b9-4429-9c49-91975ca15fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_by_id(data):\n",
    "    # Dictionary to hold the smaller DataFrames\n",
    "    dataframes = {}\n",
    "    unique_ids = data['ID'].unique()\n",
    "    for uid in unique_ids:\n",
    "        dataframes[uid] = data[data['ID'] == uid]\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22bd6e46-8da2-43da-a6a4-6726b34ea9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segments_in_df(df, target_duration_minutes, missing_data_threshold, training_segment_minutes, testing_segment_minutes):\n",
    "    df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
    "    df = df.dropna(subset=['time'])\n",
    "\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    current_start = df['time'].iloc[0] if not df['time'].empty else None\n",
    "\n",
    "    #因為原始資料其實是20秒測量一次，所以只需timestamp長度乘3\n",
    "    target_duration = target_duration_minutes * 3\n",
    "    training_segment_seconds = training_segment_minutes * 3\n",
    "    testing_segment_seconds = testing_segment_minutes * 3\n",
    "\n",
    "    for timestamp in df['time']:\n",
    "        if timestamp - current_start <= target_duration:\n",
    "            current_segment.append(timestamp)\n",
    "        else:\n",
    "            # 檢查前幾分鐘和最後幾分鐘的缺失數據比例\n",
    "            first_period = [t for t in current_segment if t - current_start <= training_segment_seconds]\n",
    "            last_period = [t for t in current_segment if timestamp - t <= testing_segment_seconds]\n",
    "\n",
    "            if len(first_period) >= (training_segment_seconds * (1 - missing_data_threshold)) and len(last_period) >= (testing_segment_seconds * (1 - missing_data_threshold)):\n",
    "                segments.append((current_segment[0], current_segment[-1]))\n",
    "\n",
    "            current_segment = [timestamp]\n",
    "            current_start = timestamp\n",
    "\n",
    "    # 檢查最後一個片段\n",
    "    first_period = [t for t in current_segment if t - current_start <= training_segment_seconds]\n",
    "    last_period = [t for t in current_segment if timestamp - t <= testing_segment_seconds]\n",
    "\n",
    "    if len(current_segment) >= (target_duration * (1 - missing_data_threshold)) and len(first_period) >= (training_segment_seconds * (1 - missing_data_threshold)) and len(last_period) >= (testing_segment_seconds * (1 - missing_data_threshold)):\n",
    "        segments.append((current_segment[0], current_segment[-1]))\n",
    "\n",
    "    return segments\n",
    "\n",
    "def calculate_segment_counts(results):\n",
    "    # 計算每個工作表中的片段數量\n",
    "    segment_counts = {sheet: len(segments) for sheet, segments in results.items()}\n",
    "    df_segment_counts = pd.DataFrame.from_dict(segment_counts, orient='index', columns=['Segment Count'])\n",
    "    total_segments = sum(segment_counts.values())\n",
    "    return df_segment_counts, total_segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760dec2b-e172-4d1b-b7f5-e59375315a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(df, segment_number):\n",
    "    # 新增一列表示 segment 編號\n",
    "    df['Segment_Number'] = segment_number\n",
    "    return df\n",
    "\n",
    "# 定義保存處理後的 segment 到 DataFrame 的函數\n",
    "def save_processed_segments_to_df(df, segments, combined_df, segment_start_number):\n",
    "    for i, (start, end) in enumerate(segments):\n",
    "        segment_df = df[(df['time'] >= start) & (df['time'] <= end)].copy()\n",
    "        segment_number = segment_start_number + i\n",
    "        segment_df = process_segment(segment_df, segment_number)\n",
    "        combined_df = pd.concat([combined_df, segment_df], ignore_index=True)\n",
    "    return combined_df, segment_start_number + len(segments)\n",
    "\n",
    "# 初始化一個空的 DataFrame 用於保存合併結果\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f94de99-6872-4bf3-a375-ff2f45690a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_timestamps_intervals(df):\n",
    "    segments = df['Segment_Number'].unique()\n",
    "    for segment in segments:\n",
    "        segment_df = df[df['Segment_Number'] == segment]\n",
    "        if not segment_df.empty:\n",
    "            # 計算新時間戳並保持間隔\n",
    "            new_timestamps = segment_df['time'] - segment_df['time'].iloc[0] + 1\n",
    "            df.loc[df['Segment_Number'] == segment, 'time'] = new_timestamps\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d6396e5-b67c-4846-9ba5-d99bc6530949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_extend_segments(df, target_duration_minutes, fill_method, fill_value):\n",
    "    target_length = target_duration_minutes * 3\n",
    "    df_list = []\n",
    "    segments = df['Segment_Number'].unique()\n",
    "\n",
    "    # Convert time to integers\n",
    "    df['time'] = df['time'].astype(int)\n",
    "\n",
    "    for segment in segments:\n",
    "        segment_df = df[df['Segment_Number'] == segment].copy()\n",
    "        segment_df = segment_df.drop_duplicates(subset='time')  # Drop duplicates\n",
    "        segment_df.set_index('time', inplace=True)\n",
    "\n",
    "        # Create a complete index range\n",
    "        idx = pd.RangeIndex(start=segment_df.index.min(), stop=segment_df.index.max(), step=1)\n",
    "\n",
    "        # Reindex and fill missing values based on fill_method\n",
    "        if fill_method == 'ffill':\n",
    "            segment_df = segment_df.reindex(idx).ffill()\n",
    "        elif fill_method == 'bfill':\n",
    "            segment_df = segment_df.reindex(idx).bfill()\n",
    "        elif fill_method == 'pad':\n",
    "            segment_df = segment_df.reindex(idx).pad()\n",
    "        elif fill_method == 'interpolate':\n",
    "            segment_df = segment_df.reindex(idx).interpolate(method='linear')\n",
    "        elif fill_method == 'fill_value' and fill_value is not None:\n",
    "            segment_df = segment_df.reindex(idx).fillna(fill_value)\n",
    "        elif fill_method == 'nan':\n",
    "            segment_df = segment_df.reindex(idx)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported fill_method: {fill_method}\")\n",
    "\n",
    "        # Check if the segment length is less than the target length\n",
    "        if len(segment_df) < target_length:\n",
    "            last_valid_index = segment_df.index[-1]\n",
    "            extend_idx = pd.RangeIndex(start=last_valid_index + 1, stop=last_valid_index + 1 + target_length - len(segment_df))\n",
    "\n",
    "            # Create an extension DataFrame with the same columns, filled with NaN values\n",
    "            if fill_method == 'nan':\n",
    "                extend_df = pd.DataFrame(index=extend_idx, columns=segment_df.columns)\n",
    "            else:\n",
    "                last_valid_row = segment_df.iloc[-1]\n",
    "                extend_df = pd.DataFrame([last_valid_row] * len(extend_idx), index=extend_idx)\n",
    "\n",
    "            # Concatenate the original and extension DataFrames\n",
    "            segment_df = pd.concat([segment_df, extend_df])\n",
    "\n",
    "        # Ensure the 'Segment_Number' column is correctly set\n",
    "        segment_df['Segment_Number'] = segment\n",
    "        df_list.append(segment_df.reset_index())\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b30836-1f91-4140-a80a-b43c6c07c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_segments(df, training_segment_minutes, testing_segment_minutes):\n",
    "    training_length = training_segment_minutes * 3\n",
    "    testing_length = testing_segment_minutes * 3\n",
    "    \n",
    "    X_set = pd.DataFrame()\n",
    "    Y_set = pd.DataFrame()\n",
    "    window_set = pd.DataFrame()\n",
    "    \n",
    "    segments = df['Segment_Number'].unique()\n",
    "    \n",
    "    for segment in segments:\n",
    "        segment_df = df[df['Segment_Number'] == segment].copy()\n",
    "        \n",
    "        X_set = pd.concat([X_set, segment_df.head(training_length)], ignore_index=True)\n",
    "        Y_set = pd.concat([Y_set, segment_df.tail(testing_length)], ignore_index=True)\n",
    "        \n",
    "        if len(segment_df) > training_length + testing_length:\n",
    "            window_set = pd.concat([window_set, segment_df.iloc[training_length:-testing_length]], ignore_index=True)\n",
    "        else:\n",
    "            window_set = pd.concat([window_set, segment_df.iloc[training_length:]], ignore_index=True)\n",
    "    \n",
    "    return X_set, Y_set, window_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4f585e-3196-4b1b-9281-5f95ce261499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Y_Set_Label(Y_set, threshold=65):\n",
    "    # 获取所有唯一的 Segment_Number\n",
    "    segments = Y_set['Segment_Number'].unique()\n",
    "    \n",
    "    # 初始化一个 numpy 数组来存储每个 segment 的结果\n",
    "    np_Y_set = np.zeros(len(segments), dtype=int)\n",
    "    \n",
    "    for i, segment in enumerate(segments):\n",
    "        segment_df = Y_set[Y_set['Segment_Number'] == segment]\n",
    "        if (segment_df['MAP'] < threshold).any():\n",
    "            np_Y_set[i] = 1\n",
    "    \n",
    "    # 统计有多少个1\n",
    "    count_of_ones = np.sum(np_Y_set)\n",
    "    \n",
    "    return np_Y_set, count_of_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b20f096b-06f7-4b46-9ed7-f955ed36b9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
      "C:\\Users\\ian11\\AppData\\Local\\Temp\\ipykernel_14544\\2029519166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time'] = pd.to_numeric(df['time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Segment Count\n",
      "#_1               2\n",
      "#_2              22\n",
      "#_3               4\n",
      "#_4              24\n",
      "#_5               0\n",
      "#_6               2\n",
      "#_7              12\n",
      "#_8               5\n",
      "#_9              22\n",
      "#_10              8\n",
      "#_11             10\n",
      "#_12             20\n",
      "#_13             51\n",
      "#_14             33\n",
      "#_15             49\n",
      "#_16             29\n",
      "#_17              1\n",
      "#_18              7\n",
      "#_19             47\n",
      "#_20             29\n",
      "#_21             23\n",
      "#_22              9\n",
      "#_23              3\n",
      "#_24              2\n",
      "#_25              2\n",
      "#_26              2\n",
      "#_27              1\n",
      "#_28              3\n",
      "Total number of segments: 422\n"
     ]
    }
   ],
   "source": [
    "#以ID分割df\n",
    "split_dfs=split_dataframe_by_id(data)\n",
    "\n",
    "#設定需求，獲取符合需求的segment\n",
    "target_duration_minutes=20   #觀察區間+window+預測區間的分鐘數\n",
    "missing_data_threshold=0.40  #觀察區間及預測區間容許的missing data比例\n",
    "training_segment_minutes=10  #觀察區間的長度\n",
    "testing_segment_minutes=10   #預測區間的長度\n",
    "segment_start_number=1\n",
    "fill_method='ffill'\n",
    "fill_value=None\n",
    "selected_segments = {}\n",
    "\n",
    "for key, df in split_dfs.items():\n",
    "    try:\n",
    "        selected_segments[key] = find_segments_in_df(df,\n",
    "                                                     target_duration_minutes, \n",
    "                                                     missing_data_threshold,\n",
    "                                                     training_segment_minutes,\n",
    "                                                     testing_segment_minutes)\n",
    "    except Exception as e:\n",
    "        selected_segments[key] = str(e)\n",
    "\n",
    "\n",
    "# 計算 segment 的數量\n",
    "df_segment_counts, total_segments = calculate_segment_counts(selected_segments)\n",
    "\n",
    "print(df_segment_counts)\n",
    "print(\"Total number of segments:\", total_segments)\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# 處理並合併所有區間到一個 DataFrame\n",
    "for key, segments in selected_segments.items():\n",
    "    if isinstance(segments, list):  # 確認結果是 segment 的列表\n",
    "        combined_df, segment_start_number = save_processed_segments_to_df(split_dfs[key], segments, combined_df, segment_start_number)\n",
    "\n",
    "\n",
    "\n",
    "readjusted_df = adjust_timestamps_intervals(combined_df)\n",
    "extended_df = fill_and_extend_segments(readjusted_df,\n",
    "                                      target_duration_minutes,\n",
    "                                      fill_method,\n",
    "                                      fill_value=None)\n",
    "extended_df.rename(columns={'index': 'timepoint'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bddcb05-7774-4175-9d94-b87db29d0060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timepoint</th>\n",
       "      <th>si1m</th>\n",
       "      <th>CO</th>\n",
       "      <th>CI</th>\n",
       "      <th>SV</th>\n",
       "      <th>SVI</th>\n",
       "      <th>SVV</th>\n",
       "      <th>SVR</th>\n",
       "      <th>SVRI</th>\n",
       "      <th>PR</th>\n",
       "      <th>SYS</th>\n",
       "      <th>DIA</th>\n",
       "      <th>MAP</th>\n",
       "      <th>ID</th>\n",
       "      <th>Segment_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>44.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>#_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>#_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>#_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>#_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>#_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25315</th>\n",
       "      <td>56</td>\n",
       "      <td>Y</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>#_28</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25316</th>\n",
       "      <td>57</td>\n",
       "      <td>Y</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>#_28</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25317</th>\n",
       "      <td>58</td>\n",
       "      <td>Y</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>#_28</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25318</th>\n",
       "      <td>59</td>\n",
       "      <td>Y</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>#_28</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25319</th>\n",
       "      <td>60</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>#_28</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25320 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timepoint si1m   CO   CI    SV   SVI   SVV     SVR    SVRI     PR  \\\n",
       "0              1    Y  4.3  2.6  44.0  27.0   5.0  1673.0  2745.0   98.0   \n",
       "1              2    Y  4.9  3.0  52.0  31.0  10.0  1525.0  2500.0   96.0   \n",
       "2              3    Y  4.9  3.0  51.0  31.0  10.0  1520.0  2495.0   96.0   \n",
       "3              4    N  5.2  3.2  51.0  31.0  10.0  1598.0  2620.0  101.0   \n",
       "4              5    N  5.1  3.1  52.0  32.0   7.0  1678.0  2750.0   98.0   \n",
       "...          ...  ...  ...  ...   ...   ...   ...     ...     ...    ...   \n",
       "25315         56    Y  6.2  3.4  58.0  32.0  15.0   660.0  1195.0  108.0   \n",
       "25316         57    Y  5.9  3.2  56.0  31.0  11.0   705.0  1275.0  106.0   \n",
       "25317         58    Y  5.8  3.2  55.0  30.0  14.0   753.0  1360.0  106.0   \n",
       "25318         59    Y  6.2  3.4  58.0  32.0   7.0   703.0  1270.0  107.0   \n",
       "25319         60    Y  4.9  2.7  46.0  25.0   7.0  1108.0  2005.0  107.0   \n",
       "\n",
       "         SYS   DIA    MAP    ID  Segment_Number  \n",
       "0      132.0  78.0   97.0   #_1               1  \n",
       "1      143.0  80.0  102.0   #_1               1  \n",
       "2      137.0  86.0  101.0   #_1               1  \n",
       "3      157.0  86.0  111.0   #_1               1  \n",
       "4      158.0  85.0  114.0   #_1               1  \n",
       "...      ...   ...    ...   ...             ...  \n",
       "25315   80.0  51.0   59.0  #_28             422  \n",
       "25316   81.0  52.0   60.0  #_28             422  \n",
       "25317   82.0  54.0   63.0  #_28             422  \n",
       "25318   83.0  54.0   63.0  #_28             422  \n",
       "25319   94.0  69.0   76.0  #_28             422  \n",
       "\n",
       "[25320 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa87aba-1fa3-4f02-b9a6-f83cd1ffecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set, Y_set, window_set = split_segments(extended_df, training_segment_minutes, testing_segment_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a61161fd-d084-439e-bfe7-779b127f8502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422,)\n",
      "(422, 11, 30)\n",
      "Count of 1: 112\n"
     ]
    }
   ],
   "source": [
    "np_Y_set, count_of_ones = Get_Y_Set_Label(Y_set, threshold=65)\n",
    "\n",
    "features = ['CO', 'CI', 'SV', 'SVI', 'SVV', 'SVR', 'SVRI', 'PR', 'SYS', 'DIA', 'MAP']\n",
    "\n",
    "grouped_data = X_set.groupby('Segment_Number')[features]\n",
    "\n",
    "# Collect the feature values for each group into a list\n",
    "np_segments = [group.values for _, group in grouped_data]\n",
    "\n",
    "# Stack these lists into a 3D numpy array\n",
    "np_X_set = np.array(np_segments)\n",
    "np_X_set = np_X_set.transpose(0, 2, 1)\n",
    "\n",
    "# Display the shape of the resulting array\n",
    "\n",
    "print(np_Y_set.shape)\n",
    "print(np_X_set.shape)\n",
    "print(\"Count of 1:\", count_of_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b0801cc-383a-4262-9cf3-2acb97b51fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indices = np.random.permutation(np_X_set.shape[0])\n",
    "\n",
    "# 使用打乱的索引来打乱 array_3d 和 y_set\n",
    "np_X_set_shuffled = np_X_set[shuffle_indices].astype(np.float32)  # 转换为 float32 类型\n",
    "np_Y_set_shuffled = np_Y_set[shuffle_indices].astype(np.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f9c1e4-9c85-45b0-8832-7c8fc7ff0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = np_X_set_shuffled.shape[0]\n",
    "n_train = int(0.6 * n_total)\n",
    "n_val = int(0.2 * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "# 切割训练集、验证集和测试集\n",
    "X_train = np_X_set_shuffled[:n_train]\n",
    "Y_train = np_Y_set_shuffled[:n_train]\n",
    "\n",
    "X_val = np_X_set_shuffled[n_train:n_train+n_val]\n",
    "Y_val = np_Y_set_shuffled[n_train:n_train+n_val]\n",
    "\n",
    "X_test = np_X_set_shuffled[n_train+n_val:]\n",
    "Y_test = np_Y_set_shuffled[n_train+n_val:]\n",
    "\n",
    "# 对每个特征进行缩放\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    scalers[i] = MinMaxScaler()\n",
    "    \n",
    "    # Reshape each feature's time points for scaling\n",
    "    X_train_feature = X_train[:, i, :].reshape(-1, 1)\n",
    "    X_val_feature = X_val[:, i, :].reshape(-1, 1)\n",
    "    X_test_feature = X_test[:, i, :].reshape(-1, 1)\n",
    "    \n",
    "    # Fit the scaler on the training data for this feature\n",
    "    scalers[i].fit(X_train_feature)\n",
    "    \n",
    "    # Transform the training, validation, and testing data for this feature\n",
    "    X_train[:, i, :] = scalers[i].transform(X_train_feature).reshape(n_train, -1)\n",
    "    X_val[:, i, :] = scalers[i].transform(X_val_feature).reshape(n_val, -1)\n",
    "    X_test[:, i, :] = scalers[i].transform(X_test_feature).reshape(n_test, -1)\n",
    "\n",
    "# 保存切分后的数据集\n",
    "np.save('X_train_ffill.npy', X_train)\n",
    "np.save('Y_train_ffill.npy', Y_train)\n",
    "np.save('X_val_ffill.npy', X_val)\n",
    "np.save('Y_val_ffill.npy', Y_val)\n",
    "np.save('X_test_ffill.npy', X_test)\n",
    "np.save('Y_test_ffill.npy', Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b14e3-e14e-4688-a1f9-faf2b71c5beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
